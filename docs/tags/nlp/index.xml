<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>NLP on vesey.tech</title>
    <link>https://vesey.tech/tags/nlp/</link>
    <description>Recent content in NLP on vesey.tech</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 02 Oct 2017 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://vesey.tech/tags/nlp/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>MarkBot</title>
      <link>https://vesey.tech/items/markbot/</link>
      <pubDate>Mon, 02 Oct 2017 00:00:00 +0000</pubDate>
      <guid>https://vesey.tech/items/markbot/</guid>
      <description>&lt;p&gt;I&amp;rsquo;ve always had a love for large datasets and the interesting things one can do with them, so when my roommate sent me his entire Google Hangouts and Facebook chat history, I knew what I had to do.&lt;/p&gt;&#xA;&lt;h1 id=&#34;enter-markbot&#34;&gt;Enter MarkBot&lt;/h1&gt;&#xA;&lt;h2 id=&#34;goals&#34;&gt;Goals&lt;/h2&gt;&#xA;&lt;p&gt;In the past, I&amp;rsquo;ve implemented plenty of basic character-level RNNs and trained them on all sorts of text corpora, but this time I wanted to try something different, and utilize word embeddings to try and produce a more coherent Mark-based chatbot. My thought process goes like so:&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
